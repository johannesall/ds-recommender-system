{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Build A Collaborative Filtering Movie Recommender System with Surprise\n",
    "\n",
    "In this exercise, you will build a collaborative filtering movie recommender system using either the `KNNWithMeans` or `SVD` algorithm from the `Scikit-Surprise` library. The dataset used is the combined Movielens dataset contained in the  `ratings_movies.csv` file that you have obtained at the end of the [previous exercise](./02_exercise_most_popular.ipynb#save-the-combined-dataframe-to-a-csv-file) after merging the `ratings.csv` and `movies.csv` files from the Movielens dataset. \n",
    "\n",
    "**Instructions**:\n",
    "1. Load the combined Movielens dataset from the `ratings_movies.csv` file.\n",
    "2. Create a `Reader` object, mapping the rating scale from 0.5 to 5.\n",
    "3. Load the dataset into a `Dataset` object, using the columns `['userId', 'movieId', 'rating']`.\n",
    "4. Split the dataset into training and testing sets using the `train_test_split` method from the `model_selection` module.\n",
    "5. Train a collaborative filtering model using either the `KNNWithMeans` or `SVD` algorithm.\n",
    "6. Make predictions on the test set and evaluate the model using the `RMSE` metric.\n",
    "7. Generate top-N movie recommendations for a given user ID using the `get_top_n` function provided in\n",
    "   + [KNN notebook](./03_collaborative_filtering_similarity.ipynb#k-nearest-neighbors).\n",
    "   + [SVD notebook](./03_collaborative_filtering_matrix_factorization.ipynb#singular-value-decomposition).\n",
    "8. Optionally, make movie recommendations for a new user by providing a list of movie ratings. Just follow the steps provided in \n",
    "   + [KNN notebook](./03_collaborative_filtering_similarity.ipynb#predictions-for-a-new-user).\n",
    "   + [SVD notebook](./03_collaborative_filtering_matrix_factorization.ipynb#predictions-for-a-new-user)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import KNNWithMeans, SVD\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the combined Movielens dataset from the `ratings_movies.csv` file.\n",
    "ratings_movies = pd.read_csv('./data/ratings_movies.csv')\n",
    "ratings_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a `Reader` object using the `rating_scale` parameter set to `(0.5, 5)`.\n",
    "reader = Reader(rating_scale=(0.5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset into a `Dataset` object, using the columns [`userId`, `movieId`, `rating`].\n",
    "data = Dataset.load_from_df(ratings_movies[['userId', 'movieId','rating']], reader)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets using the `train_test_split` method from the `model_selection` module.\n",
    "trainset, testset = train_test_split(data, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Train a collaborative filtering model using the `KNNWithMeans` algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a `KNNWithMeans` model with a cosine similarity.\n",
    "simulation_options = {\n",
    "    'name': 'cosine',\n",
    "    'user_based': False # Item-based\n",
    "}\n",
    "knn = KNNWithMeans(sim_options=simulation_options, k=40)\n",
    "\n",
    "# Fit the model to the training data.\n",
    "knn.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model on the test data.\n",
    "predictions_knn = knn.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the RMSE of the model.\n",
    "accuracy.rmse(predictions_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(predictions, userId, n=10):\n",
    "    \"\"\" Return the top-N recommendation for each user from a set of predictions.\n",
    "    \n",
    "    Args:\n",
    "    predictions(list of Prediction objects): The list of predictions, as\n",
    "        returned by the test method of an algorithm.\n",
    "    n(int): The number of recommendation to output for each user. Default\n",
    "        is 10.\n",
    "    \n",
    "    \n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of\n",
    "        size n.\n",
    "    \"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    \n",
    "    for user_id, item_id, actual_rating, estimated_rating, _ in predictions:\n",
    "        top_n[user_id].append((item_id, estimated_rating))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for user_id, estimated_ratings in top_n.items():\n",
    "        estimated_ratings.sort(key=lambda x: x[1], reverse=True) # sort by rating estimation, descending. x[1] is the estimated rating. \n",
    "        top_n[user_id] = estimated_ratings[:n]\n",
    "\n",
    "    return top_n[userId]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the `get_top_n` function to get the top 10 recommendations for a particular user.\n",
    "userId = 100\n",
    "top_n = get_top_n(predictions_knn, userId= userId, n=10)\n",
    "top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the movie ID from the top_n \n",
    "movie_ids = [movie_id for movie_id, _ in top_n] # List comprehension\n",
    "movie_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the recommened movie titles\n",
    "recommended_movies = ratings_movies.set_index('movieId').loc[movie_ids, 'title'].drop_duplicates().to_list()\n",
    "print(f\"Recommended movies for user {userId} are: \", recommended_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Train a collaborative filtering model using the SVD algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a `SVD` model.\n",
    "svd = SVD(n_factors=100, n_epochs=20, lr_all=0.005, reg_all=0.02, random_state=42)\n",
    "\n",
    "# Fit the model to the training data.\n",
    "svd.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the ratings for the testset\n",
    "predictions_svd = svd.test(testset)\n",
    "\n",
    "# Calculate the RMSE of the model.\n",
    "print(\"RMSE for SVD model is: \", accuracy.rmse(predictions_svd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the `get_top_n` function to get the top 10 recommendations for a particular user.\n",
    "top_n_svd = get_top_n(predictions_svd, userId= userId, n=10)\n",
    "top_n_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the movie ID from the top_n _svd\n",
    "movie_ids_svd = [movie_id for movie_id, _ in top_n_svd] # List comprehension\n",
    "movie_ids_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the recommened movie titles with SVD\n",
    "recommended_movies_svd = ratings_movies.set_index('movieId').loc[movie_ids_svd, 'title'].drop_duplicates().to_list()\n",
    "print(f\"Recommended movies for user {userId} are: \", recommended_movies_svd)\n",
    "recommended_movies = ratings_movies.set_index('movieId').loc[movie_ids, 'title'].drop_duplicates().to_list()\n",
    "print(f\"Recommended movies for user {userId} are: \", recommended_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "surprise_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
