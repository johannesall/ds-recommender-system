{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative filtering - Matrix Factorization with Surprise\n",
    "\n",
    "In this notebook, you will learn another collaborative filtering technique called Matrix Factorization, more specifically we will use `Singular Value Decomposition (SVD)` to factorize the **user-item** interaction matrix. \n",
    "The **benefit** of using matrix factorization is that it can **capture** the **latent features** underlying the interactions between users and items. This allows us to make recommendations based on the user-item interaction matrix even if we have missing values.\n",
    "\n",
    "We will use again  the Scikit-Surprise library to build a **SVD model** and make recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first we import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import copy\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import KNNWithMeans, SVD\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load our rating data. It contains the necessary `user_id`, `item_id` and the `rating` users gave to the fish items. Additionally it has some nice-to-have information about the fish items. There are 500 users with 300 rated fishes each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset from the csv file\n",
    "df = pd.read_csv('data/user_item_ratings.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Scikit-Surprise library we want to use does not work with pandas DataFrames but with Dataset objects. So we need to create a Dataset object from our DataFrame. We also need to define the possible ratings with the Reader class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines possible ratings\n",
    "reader = Reader(rating_scale=(1, 10))\n",
    "# Loads Pandas dataframe\n",
    "data = Dataset.load_from_df(df[[\"user_id\", \"item_id\", \"rating\"]], reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to validate our models we need to split our data into a trainset, which we will use to train our models. And a testset to validate the ability of our models to predict on unseen data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and test set\n",
    "trainset, testset = train_test_split(data, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with the modeling!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Singular Value Decomposition\n",
    "\n",
    "Another way to estimate the user ratings is **Singular Value Decomposition (SVD)**. **Singular value decomposition** is a matrix decomposition, where we decompose a given **m x n** matrix $A$ into three matrices **$U$**, $\\Sigma$ and $V$ with the dimensions **m x r**, **r x r** and **n x r** respectively. Here r is usually small compared to m and n. And $\\Sigma$ is non-zero only on the diagonal.\n",
    "\n",
    "![](./images/SVD_USigmaV.png) \n",
    "\n",
    "By decomposing the matrix $A$ in this way, we drastically reduce the number of elements to be stored. Let $m = n = 100$ and $r = 5$ then the original matrix $A$ has $100 \\times 100 = 10000$ elements. Whereas $U$ has $100 \\times 5 = 500$, $\\Sigma$ has $5$ (only diagonal elements) and $V$ again has $100 \\times 5 = 500$ elements leading to a total of only $1005$ elements as opposed to the $10000$ elements of the original matrix $A$.\n",
    "\n",
    "The rows of m of our user-item-rating matrix $A$ refer to the users and the n columns to the items (fishes in our case). The introduced **latent factors** (r in above example) can be interpreted as characteristics of the users for $U$ and item characteristics for $V$. So the latent factors are features of items or users, generated by our **SVD algorithm**. In our case they can tell us how much a user likes a certain `visual_effect` or how much a fish shows said `visual_effect`. $\\Sigma$ then models the importance of each `visual_effect`.\n",
    "\n",
    "The **actual implementation** of the algorithm in the **surprise library** will be outlined here to show an example of how to find an optimal decomposition. It became popular due to Simon Funk and his contribution to the Netflix competition. \n",
    "\n",
    "Here the rating that user u gives item i is denoted by $r_{ui}$ and will be estimated by:\n",
    "\n",
    "\n",
    "$$\n",
    "\\hat r_{ui} = \\mu + b_u + b_i + q^T_i p_u\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "- (u,i): **user-item pair**\n",
    "- $\\mu$: **average rating of all items**\n",
    "- $b_i$: **average rating of item i minus $\\mu$**\n",
    "- $b_u$: **average rating given by user u minus $\\mu$**\n",
    "- $q_i$: **latent item factor vector**\n",
    "- $p_u$: **latent user factor vector**\n",
    "- $q^T_i p_u$: **dot product of the latent factors**\n",
    "\n",
    "As shown in the formula above, the matrix decomposition is done by using only two matrices **$Q$** and **$P$**. The matrix **$Q$** contains the latent factors of the items and the matrix **$P$** contains the latent factors of the users. The latent factors and the biases are learned by minimizing the regularized squared error:\n",
    "\n",
    "\n",
    "$$\n",
    "\\sum_{r_{ui} \\in R_{train}}(r_{ui} - \\hat r_{ui})^2 + \\lambda(b_i^2 + b_u^2 + ||q_i||^2 + ||p_u||^2)\n",
    "$$\n",
    "\n",
    "The minimization is performed by a simple stochastic gradient descent (parameters are updated iteratively):\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "b_u &\\leftarrow b_u + \\gamma(e_{ui} - \\lambda b_u)\\\\\n",
    "b_i &\\leftarrow b_i + \\gamma(e_{ui} - \\lambda b_i)\\\\\n",
    "p_u &\\leftarrow p_u + \\gamma(e_{ui}*q_i - \\lambda p_u)\\\\\n",
    "q_i &\\leftarrow q_i + \\gamma(e_{ui}*p_u - \\lambda q_i)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "where $e_{ui} = r_{ui} - \\hat r_{ui}$, $\\gamma$ is the **learning rat**e and $\\lambda$ is the **regularization parameter**.\n",
    "\n",
    "Now that we understand **SVD** let us train the algorithm on our train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use the famous SVD algorithm.\n",
    "algo_svd = SVD(n_factors=100, n_epochs=20, lr_all=0.005, reg_all=0.02,random_state=42)\n",
    "\n",
    "# Train the algorithm on the trainset, and \n",
    "algo_svd.fit(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **SVD** class takes a few parameters:\n",
    "+ `n_factors`: The number of factors. Default is 100.\n",
    "+ `n_epochs`: The number of iteration of the SGD procedure. Default is 20.\n",
    "+ `lr_all`: The learning rate for all parameters. Default is 0.005.\n",
    "+ `reg_all`: The regularization term for all parameters. Default is 0.02.   \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict ratings for the testset\n",
    "predictions = algo_svd.test(testset)\n",
    "\n",
    "# Then compute RMSE\n",
    "print(f\"RMSE: {accuracy.rmse(predictions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: `.test()` is a method that evaluates the entire test set and returns the predictions as a list of `Prediction` objects. Each object details the `user ID`, `item ID`, `actual rating`, and `estimated rating`. Additionally, the `.predict()` method is used for predicting the rating for a single user-item pair, returning a `Prediction` object that includes the estimated rating among other details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in predictions:\n",
    "    print(f\"user id:{element.uid}\", f\"item id:{element.iid}\", f\"estimated rating:{element.est}\", f\"real rating:{element.r_ui}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the top 10 recommendations for a specific user. Though there is no implementation of this in surprise the documentation provides a function `get_top_n` that returns the top-N recommendations, if we provide the predictions of our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(predictions, n=10):\n",
    "    \"\"\" Return the top-N recommendation for each user from a set of predictions.\n",
    "    \n",
    "    Args:\n",
    "    predictions(list of Prediction objects): The list of predictions, as\n",
    "        returned by the test method of an algorithm.\n",
    "    n(int): The number of recommendation to output for each user. Default\n",
    "        is 10.\n",
    "    \n",
    "    \n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of\n",
    "        size n.\n",
    "    \"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    \n",
    "    for user_id, item_id, actual_rating, estimated_rating, _ in predictions:\n",
    "        top_n[user_id].append((item_id, estimated_rating))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for user_id, estimated_ratings in top_n.items():\n",
    "        estimated_ratings.sort(key=lambda x: x[1], reverse=True) # sort by rating estimation, descending. x[1] is the estimated rating. \n",
    "        top_n[user_id] = estimated_ratings[:n]\n",
    "\n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we will get is a list of ten tuples (item_id, estimated_rating). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the top 10 recommendations for each user\n",
    "top_10 = get_top_n(predictions, n=10)\n",
    "top_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the recommended items for a specific user\n",
    "user_id = 201   # user id\n",
    "# 10 best rated items for user id\n",
    "top_10[user_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make list of the top 10 item id's `top_iids`. And use it with the original fishes dataframe to get some characteristics of our recommended fishes. Apparently our user liked especially colorful fishes the most :)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The top 10 recommendations for user_id 201 are:\n",
    "top_items_id_user_id = []\n",
    "for item_id, estimated_rating in top_10[user_id]:\n",
    "    print(f\"item id: {item_id}, estimated rating: {estimated_rating}\")\n",
    "    top_items_id_user_id.append(item_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_items_id_user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the name of the recommended items\n",
    "recommended_fishes = df.set_index('item_id').loc[top_items_id_user_id][['name','fish_group','visual_effect']].drop_duplicates().copy()\n",
    "recommended_fishes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Grid Search\n",
    "\n",
    "The SVD algorithm in the surprise library comes with a lot of hyper parameters which influence the performance of the model. To search for optimal hyper parameters in machine learning Grid search is used. It performs an exhaustive search over a prior defined parameter space using cross-validation (hence the CV suffix). That means it will evaluate all of the possible parameter combinations of the search space in order to find and return the best combination.\n",
    "\n",
    "This task, however, starts to become very time-consuming if there are many hyperparameters and the search space is huge. As you can see for cv= 3 (number of folds that will be evaluated) and for 3 parameters with 2 values, thus 8 combinations, the GridSearchCV runs 24 modelling steps in order to just come up with the best values for the three parameters.\n",
    "\n",
    "Please feel free to try out different values and beat the default ones from our prediction above ;) and if you still have time improve your result even further!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"n_epochs\": [10, 20],       # The number of iteration of the SGD procedure. Default is 20.\n",
    "    \"lr_all\": [0.002, 0.005],   # The learning rate for all parameters. Default is 0.005.\n",
    "    \"reg_all\": [0.02, 0.04]     # The regularization term for all parameters. Default is 0.02.\n",
    "}\n",
    "gs = GridSearchCV(SVD, param_grid, measures=[\"rmse\", \"mae\"], cv=3)\n",
    "\n",
    "gs.fit(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"best RMSE:\")\n",
    "print(gs.best_score[\"rmse\"])\n",
    "print(\"best parameters:\")\n",
    "print(gs.best_params[\"rmse\"])\n",
    "print(\"best MAE:\")\n",
    "print(gs.best_score[\"mae\"])\n",
    "print(\"best parameters:\")\n",
    "print(gs.best_params[\"mae\"])\n",
    "print(\"best estimator:\")\n",
    "print(gs.best_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model\n",
    "best_svd = gs.best_estimator[\"mae\"]\n",
    "# Since GridSearchCV does not train the best_estimator on full data automatically, we need to retrain it:\n",
    "best_svd.fit(trainset)\n",
    "\n",
    "print(f\"{accuracy.mae(predictions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that getting the best score in recommender systems is not always the best for your business. Very accurate scores can lead to recommendations perceived as boring by the user, because the items are too similar to items they already know. So always keep the user in mind when optimizing your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions for a new user\n",
    "Let's imagine we have a new user who has not rated any fish yet. This is a common issue called the **cold start problem**. For this user we could use the **most popular** fishes as a recommendation. This is a simple but effective way to start with. We can also ask the user to rate some items and then use the **user-based** or **item-based** collaborative filtering to make recommendations. One could directly use the trained model to make predictions for the new user or retrain the model with the new user's ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will follow the approach of asking the new user to rate some items and then use the latent factors of the SVD model to make recommendations according to the equation:\n",
    "\n",
    "$$\n",
    "\\hat r_{ui} = \\mu + b_u + b_i + q^T_i p_u\n",
    "$$\n",
    "\n",
    "First, we will need to estimate the user latent feature matrix **p** based on the new user's ratings and the item latent feature matrix **q** from the model. We can then use the equation above to predict the ratings for the new user. We will then recommend the top 10 items with the highest predicted ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect Ratings from New User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_ratings = [\n",
    "    {\"user_id\": 500, \"item_id\": 1, \"rating\": 10},\n",
    "    {\"user_id\": 500, \"item_id\": 2, \"rating\": 9},\n",
    "    {\"user_id\": 500, \"item_id\": 3, \"rating\": 8},\n",
    "    {\"user_id\": 500, \"item_id\": 40, \"rating\": 7},\n",
    "    {\"user_id\": 500, \"item_id\": 5, \"rating\": 6},\n",
    "    {\"user_id\": 500, \"item_id\": 6, \"rating\": 5},\n",
    "    {\"user_id\": 500, \"item_id\": 390, \"rating\": 4},\n",
    "    {\"user_id\": 500, \"item_id\": 8, \"rating\": 3},\n",
    "    {\"user_id\": 500, \"item_id\": 9, \"rating\": 2},\n",
    "    {\"user_id\": 500, \"item_id\": 10, \"rating\": 1},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe with the new user ratings\n",
    "new_user_ratings_df = pd.DataFrame(new_user_ratings)\n",
    "new_user_ratings_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate the New User's Latent Feature vecture P\n",
    "We need to estimate the userâ€™s latent feature vector that best explains the new user's provided ratings, using the known item factors from the SVD model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Items that the new user has rated\n",
    "item_ids = new_user_ratings_df[\"item_id\"].values\n",
    "item_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract the item factors q for the rated items from the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_factors = []\n",
    "for item_id in item_ids:\n",
    "    # Convert the raw id to inner id, which is in the same order of the items  as in the model\n",
    "    item_idx = algo_svd.trainset.to_inner_iid(item_id) \n",
    "    #print(item_idx)\n",
    "    # Get the item factor\n",
    "    item_factor = algo_svd.qi[item_idx]\n",
    "    #print(item_factor)\n",
    "    item_factors.append(item_factor)\n",
    "\n",
    "# Convert the list of item factors to a numpy array\n",
    "Q = np.array(item_factors)\n",
    "# Check the shape of the array\n",
    "Q.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, `Q` is a numpy array with the shape `(n_items, n_latent_factors)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract the item biases b for the rated items from the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_biases = []\n",
    "for item_id in item_ids:\n",
    "    # Convert the raw id to inner id, which is in the same order of the items  as in the model\n",
    "    item_idx = algo_svd.trainset.to_inner_iid(item_id) \n",
    "    item_bias = algo_svd.bi[item_idx]\n",
    "    item_biases.append(item_bias)\n",
    "\n",
    "b = np.array(item_biases)\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the user bias as the average of all user biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the user bias as the average of all user biases\n",
    "user_bias = np.mean(algo_svd.bu)\n",
    "user_bias\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the user latent feature vector P\n",
    "To estimate the user latent feature vector, we need to solve the following equation:\n",
    "\n",
    "$$\n",
    "\\hat r_{ui} = \\mu + b_u + b_i + q^T_i p_u\n",
    "$$\n",
    "\n",
    "For each rated item, we have the following equation:\n",
    "\n",
    "$$\n",
    "r_{ui} = \\mu + b_u + b_i + q^T_i p_u\n",
    "$$\n",
    "\n",
    "We can rewrite this equation as follows:\n",
    "\n",
    "$$\n",
    "r_{ui} - \\mu - b_i - b_u = q^T_i p_u\n",
    "$$\n",
    "\n",
    "We can then stack these equations for all rated items to form a matrix equation:\n",
    "\n",
    "$$\n",
    "R - \\mu - B - B_u = Q P_u\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $R$ is the vector of all ratings for the rated items\n",
    "- $B$ is the vector of all item biases for the rated items\n",
    "- $B_u$ is the vector of all user biases for the rated items\n",
    "- $Q$ is the matrix of all item latent feature vectors for the rated items\n",
    "- $P_u$ is the user latent feature vector we want to estimate\n",
    "- $\\mu$ is the average rating of all items\n",
    "\n",
    "\n",
    "We can solve this equation for $P_u$ using the following equation:\n",
    "\n",
    "$$\n",
    "P_u = (Q^T Q + \\lambda I)^{-1} Q^T (R - \\mu - B -B_u)\n",
    "\n",
    "$$\n",
    "\n",
    "where $\\lambda$ is the regularization parameter and $I$ is the identity matrix.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_ratings = new_user_ratings_df['rating'].values\n",
    "actual_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global average rating\n",
    "mu = algo_svd.trainset.global_mean\n",
    "mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_ratings = actual_ratings - mu - b - user_bias\n",
    "adjusted_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Q^T Q\n",
    "QTQ = np.dot(Q.T, Q)\n",
    "QTQ.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Identity matrix of size equal to the number of features\n",
    "I = np.eye(Q.shape[1])\n",
    "I.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularized matrix\n",
    "lambda_reg = 0.1\n",
    "regularized_matrix = QTQ + lambda_reg * I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse of the regularized matrix\n",
    "inv_regularized_matrix = np.linalg.inv(regularized_matrix)\n",
    "inv_regularized_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute final P_u\n",
    "P_u = inv_regularized_matrix.dot(Q.T).dot(adjusted_ratings)\n",
    "P_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_rating = mu + user_bias + b + np.dot(Q, P_u)\n",
    "estimated_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Recommendations for the New User on Items Not Yet Rated\n",
    "Now that we have estimated the new user's latent feature vector, we can use it to predict the ratings for the items not yet rated by the user. We can then recommend the top 10 items with the highest predicted ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get all items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_items = df['item_id'].unique()\n",
    "all_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the items not rated by the new user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_not_rated = np.setdiff1d(all_items, item_ids)\n",
    "items_not_rated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numpy function `np.setdiff1d` is a very efficient way to find the difference between two arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract the item factors for the items not rated by the new user from the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_factors_not_rated = []\n",
    "for item_id in items_not_rated:\n",
    "    # Convert the raw id to inner id, which is in the same order of the items as in the model\n",
    "    item_idx = algo_svd.trainset.to_inner_iid(item_id) \n",
    "    item_factor = algo_svd.qi[item_idx]\n",
    "    item_factors_not_rated.append(item_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list to a numpy array\n",
    "Q_not_rated = np.array(item_factors_not_rated)\n",
    "Q_not_rated.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract the item biases for the items not rated by the new user from the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the item biases for the items not rated by the new user from the trained model\n",
    "item_biases_not_rated = []\n",
    "for item_id in items_not_rated:\n",
    "    # Convert the raw id to inner id, which is in the same order of the items as in the model\n",
    "    item_idx = algo_svd.trainset.to_inner_iid(item_id)\n",
    "    item_bias = algo_svd.bi[item_idx]\n",
    "    item_biases_not_rated.append(item_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list to a numpy array\n",
    "b_not_rated = np.array(item_biases_not_rated)\n",
    "b_not_rated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the estimated ratings for the items not rated by the new user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "estimated_ratings_not_rated = mu + b_not_rated + user_bias + np.dot(Q_not_rated, P_u)\n",
    "estimated_ratings_not_rated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the top 10 items with the highest predicted ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_of_items_not_rated = df.set_index('item_id').loc[items_not_rated]['name'].drop_duplicates().values\n",
    "name_of_items_not_rated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with the name of the items and the estimated ratings for the items not rated by the new user\n",
    "name_estimated_ratings_not_rated_df = pd.DataFrame({\n",
    "    'name' : name_of_items_not_rated,\n",
    "    'item_id': items_not_rated,\n",
    "    'estimated_rating': estimated_ratings_not_rated\n",
    "})\n",
    "name_estimated_ratings_not_rated_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the name of the top 10 items\n",
    "top_10_items = name_estimated_ratings_not_rated_df.sort_values(by='estimated_rating', ascending=False).head(10)\n",
    "top_10_items\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In this notebook, we learned how to use collaborative filtering based on matrix factorization with Singular Value Decomposition (SVD) to make recommendations, by extracting latent features from the user-item interaction matrix. We used the Scikit-Surprise library to train an SVD model on a custom dataset of user ratings for fish items. We learnt then also how to optimize the hyperparameters of the SVD model using GridSearchCV. \n",
    "\n",
    "Finally, we made recommendations for a new user who has not rated any items yet. We estimated the new user's latent feature vector using the SVD model and made recommendations for the top 10 items with the highest predicted ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "- [Surprise Library](https://surprise.readthedocs.io/en/stable/index.html)\n",
    "- [SVD](https://surprise.readthedocs.io/en/stable/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.SVD)\n",
    "- [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
    "- [Singular Value Decomposition](https://en.wikipedia.org/wiki/Singular_value_decomposition)\n",
    "- [Collaborative Filtering](https://en.wikipedia.org/wiki/Collaborative_filtering)\n",
    "- [Netflix Prize](https://en.wikipedia.org/wiki/Netflix_Prize)\n",
    "- [Simon Funk](https://sifter.org/simon/journal/20061211.html)\n",
    "- [Cold Start Problem](https://en.wikipedia.org/wiki/Cold_start_(recommender_systems))\n",
    "- [Matrix Factorization](https://en.wikipedia.org/wiki/Matrix_factorization_(recommender_systems))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "surprise_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
